{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wKyeatapyCo",
    "outputId": "fabf86c0-611a-44e3-ec33-ef69b17906be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in ./.venv/lib/python3.13/site-packages (3.0.1)\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.13/site-packages (4.1.0)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.13/site-packages (1.11.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (0.31.2)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./.venv/lib/python3.13/site-packages (from faiss-cpu) (2.2.5)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (80.4.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 sentence-transformers faiss-cpu fastapi uvicorn pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fhqB-3nik4Nc"
   },
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import uvicorn\n",
    "from typing import List, Optional\n",
    "import os\n",
    "\n",
    "app = FastAPI(title=\"RAG Chatbot API\", description=\"Motherhood and Childcare Assistant\")\n",
    "\n",
    "# Global variables for RAG components\n",
    "chunks = None\n",
    "embedder = None\n",
    "index = None\n",
    "embeddings = None\n",
    "client = None\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str\n",
    "    max_tokens: Optional[int] = 512\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "    retrieved_context: str\n",
    "\n",
    "# ---- RAG Functions ----\n",
    "def load_pdf_chunks(pdf_path, chunk_size=500):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        full_text += page.extract_text() + \"\\n\"\n",
    "    \n",
    "    chunks = [full_text[i:i+chunk_size] for i in range(0, len(full_text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "def embed_chunks(chunks, embedder):\n",
    "    embeddings = embedder.encode(chunks)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings\n",
    "\n",
    "def retrieve_context(query, chunks, embedder, index, embeddings, top_k=3):\n",
    "    query_embedding = embedder.encode([query])\n",
    "    _, indices = index.search(np.array(query_embedding), top_k)\n",
    "    return \"\\n---\\n\".join([chunks[i] for i in indices[0]])\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    \"\"\"Initialize RAG components on startup\"\"\"\n",
    "    global chunks, embedder, index, embeddings, client\n",
    "    \n",
    "    # Load PDF and setup RAG\n",
    "    pdf_path = \"./FAQ_for_Chatbot.pdf\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise Exception(f\"PDF file not found: {pdf_path}\")\n",
    "    \n",
    "    print(\"Loading PDF and initializing RAG...\")\n",
    "    chunks = load_pdf_chunks(pdf_path)\n",
    "    embedder = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\")\n",
    "    index, embeddings = embed_chunks(chunks, embedder)\n",
    "    \n",
    "    # Initialize OpenAI client\n",
    "    client = OpenAI(\n",
    "        api_key=\"sk-titCpkply6rFBcc6326yqTJzL20JeJJ9ACekZEij4nNCpClA\",\n",
    "        base_url=\"https://api.opentyphoon.ai/v1\"\n",
    "    )\n",
    "    \n",
    "    print(\"RAG Chatbot API initialized successfully!\")\n",
    "\n",
    "@app.post(\"/chat\", response_model=ChatResponse)\n",
    "async def chat(request: ChatRequest):\n",
    "    \"\"\"Chat endpoint for the RAG chatbot\"\"\"\n",
    "    try:\n",
    "        # Retrieve relevant context\n",
    "        retrieved_context = retrieve_context(\n",
    "            request.message, chunks, embedder, index, embeddings\n",
    "        )\n",
    "        \n",
    "        # Prepare system prompt\n",
    "        system_prompt = f\"\"\"\n",
    "You are an AI assistant specialized in motherhood and childcare.\n",
    "Use the following additional context to help answer the question:\n",
    "{retrieved_context}\n",
    "\"\"\"\n",
    "        \n",
    "        # Create conversation\n",
    "        conversation = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": request.message}\n",
    "        ]\n",
    "        \n",
    "        # Get response from OpenAI\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"typhoon-v2-70b-instruct\",\n",
    "            messages=conversation,\n",
    "            max_tokens=request.max_tokens\n",
    "        )\n",
    "        \n",
    "        return ChatResponse(\n",
    "            response=response.choices[0].message.content,\n",
    "            retrieved_context=retrieved_context\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\"status\": \"healthy\", \"message\": \"RAG Chatbot API is running\"}\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"Root endpoint with API information\"\"\"\n",
    "    return {\n",
    "        \"message\": \"Welcome to RAG Chatbot API\",\n",
    "        \"endpoints\": {\n",
    "            \"chat\": \"/chat - POST request with message\",\n",
    "            \"health\": \"/health - Health check\",\n",
    "            \"docs\": \"/docs - API documentation\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBZuOm7nsYGS",
    "outputId": "e99a8636-e54a-47c0-d8ea-c0c2a1927664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ไม่ผิดปกติค่ะ ในนมแม่มีโปรตีนที่ย่อยง่าย และในน้ำนมแม่ส่วนหน้าประกอบด้วยน้ำตาลแลคโตสและโอลิโกแซคคาไรด์ ซึ่งช่วยส่งเสริมจุลินทรีย์ชนิดดีในลำไส้ รวมถึงฮอร์โมนพรอสตาแกลนดินที่กระตุ้นการเคลื่อนตัวของลำไส้ ดังนั้น ทารกที่กินนมแม่มักถ่ายบ่อยและอุจจาระเหลวได้ หากอุจจาระของทารกไม่มีมูกเลือด ไม่มีกลิ่นเหม็นเน่า ร่วมกับดูดนมได้ดี ไม่มีไข้ ไม่มีซึม หรือร้องกวนผิดปกติ คุณแม่ก็ไม่ต้องกังวลค่ะ\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Run the API Server ----\n",
    "# Uncomment the line below to start the server\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "print(\"FastAPI application created!\")\n",
    "print(\"To start the server, run in terminal: uvicorn rag_api:app --reload --port 8000\")\n",
    "print(\"Then visit: http://localhost:8000/docs for API documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Test Client Example ----\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def test_chatbot_api(message=\"ลูกกินนมแม่แล้วถ่ายบ่อยผิดปกติหรือไม่?\", port=8000):\n",
    "    url = f\"http://localhost:{port}/chat\"\n",
    "    \n",
    "    data = {\n",
    "        \"message\": message,\n",
    "        \"max_tokens\": 512\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(\"Bot Response:\")\n",
    "            print(result[\"response\"])\n",
    "            print(\"\\n--- Retrieved Context ---\")\n",
    "            print(result[\"retrieved_context\"])\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Connection error: {e}\")\n",
    "        print(\"Make sure the API server is running!\")\n",
    "\n",
    "# Uncomment to test (server must be running first)\n",
    "# test_chatbot_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use the RAG Chatbot API\n",
    "\n",
    "### 1. Start the API Server\n",
    "Run this command in your terminal:\n",
    "```bash\n",
    "uvicorn rag_api:app --reload --port 8000\n",
    "```\n",
    "\n",
    "### 2. Test the API\n",
    "- Visit `http://localhost:8000/docs` for interactive API documentation\n",
    "- Use the test client function above\n",
    "- Or make direct HTTP requests to `http://localhost:8000/chat`\n",
    "\n",
    "### 3. API Endpoints\n",
    "- `POST /chat` - Send a message to the chatbot\n",
    "- `GET /health` - Check API health status\n",
    "- `GET /` - API information\n",
    "- `GET /docs` - Interactive API documentation\n",
    "\n",
    "### 4. Request Format\n",
    "```json\n",
    "{\n",
    "  \"message\": \"Your question here\",\n",
    "  \"max_tokens\": 512\n",
    "}\n",
    "```\n",
    "\n",
    "### 5. Response Format\n",
    "```json\n",
    "{\n",
    "  \"response\": \"AI assistant's answer\",\n",
    "  \"retrieved_context\": \"Relevant context from PDF\"\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
